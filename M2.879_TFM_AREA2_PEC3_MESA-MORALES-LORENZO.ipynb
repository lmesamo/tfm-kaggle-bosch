{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\" align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\"><strong>M2.879 · TFM - Área 2- Machine Learning</strong></p>\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\"><strong>Predicción de errores en producción industrial de piezas</strong></p>\n",
    "    <p style=\"margin: 0; text-align:right;\"><strong>Lorenzo Mesa Morales</strong></p>\n",
    "    <p style=\"margin: 0; text-align:right;\">2019-2 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Nombre Consultor/a: Jerónimo Hernández González</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Nombre Profesor/a responsable de la asignatura: Jordi Casas Roma</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Implementación\n",
    "\n",
    "El documento se estructura siguiendo la metodología CRISP-DM en las siguientes secciones:\n",
    "\n",
    " <ol start=\"1\">\n",
    "  <li>Carga del conjuntos de datos</li>\n",
    "  <li>Análisis de los datos\n",
    "  <li>Preparación de los datos</li>\n",
    "    3.1 Valores nulos\n",
    "    <br>3.2 Reduccion de dimensionalidad\n",
    "    <br>3.3 Técnicas de muestreo\n",
    "  <li>Modelado</li>\n",
    "    4.1 Random Forest\n",
    "    <br>4.2 eXtreme Gradient Boosting (XGBoost)\n",
    "  <li>Evaluación</li>\n",
    "    5.1 Combinación secuencial de modelos\n",
    " </ol>\n",
    "   \n",
    "Para ello vamos a necesitar las siguientes librerías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import gc\n",
    "from collections import Counter\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.ensemble import StackingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 1. Carga del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Dada la cantidad de recursos que consume la carga de los datos se procede a mostrar un resumen de los datos que contienen cada uno de los ficheros \n",
    "<a href=\"https://www.kaggle.com/c/bosch-production-line-performance/discussion/22908\" title=\"Kaggle Discusion 22908\">[Kaggle Discusion 22908]</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "def muestra_resumen(filename): \n",
    "    rowCount=0\n",
    "    numberEmptyValues=0\n",
    "\n",
    "    with open(filename, \"rt\") as csvfile:\n",
    "        filereader = csv.reader(csvfile)\n",
    "        for curRow in filereader:\n",
    "            if rowCount == 0 :\n",
    "                headerRow=curRow\n",
    "                numberColumns=len(headerRow)\n",
    "                emptyList=['']*numberColumns  # creamos una lista para las entradas vacías\n",
    "                emptyCounter=Counter(emptyList)\n",
    "\n",
    "            else:\n",
    "                curCounter=Counter(curRow)\n",
    "                diff = curCounter-emptyCounter  # creamos una lista de valores no vacíos\n",
    "\n",
    "                numberNotEmpty=len(diff) # calculamos el tamaño de la lista\n",
    "                numEmpty=numberColumns-numberNotEmpty \n",
    "                numberEmptyValues=numberEmptyValues+numEmpty\n",
    "\n",
    "\n",
    "            rowCount=rowCount+1\n",
    "\n",
    "\n",
    "    totalnumber=rowCount*numberColumns\n",
    "    pctEmpty=100*numberEmptyValues/totalnumber\n",
    "\n",
    "    print(\"fichero analizado       :\",filename)\n",
    "    print(\"número de filas         :\",rowCount)\n",
    "    print(\"número de columnas      :\",numberColumns)\n",
    "    print(\"número de valores vacíos:\",numberEmptyValues)\n",
    "    print(\"% de valores vacíos     :\",pctEmpty)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"train_numeric.csv\"\n",
    "muestra_resumen(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"train_categorical.csv\"\n",
    "muestra_resumen(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"train_date.csv\"\n",
    "muestra_resumen(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para simplificar el trabajo y por la limitación de recursos se utilizan únicamente con los datos de tipo numérico\n",
    "\n",
    "# Se carga el conjunto de datos de entrenamiento de tipo numérico\n",
    "\n",
    "# Se toma una muestra de 100 filas para determinar los dtypes.\n",
    "df_sample = pd.read_csv('train_numeric.csv', nrows=100)\n",
    "\n",
    "# Se convierten a float32 para reducir el tamaño del dataset y optimizar los recursos\n",
    "float_cols = [c for c in df_sample if df_sample[c].dtype == \"float64\"]\n",
    "float32_cols = {c: np.float32 for c in float_cols}\n",
    "\n",
    "df_num = pd.read_csv('train_numeric.csv', engine='c', dtype={c: np.float32 for c in float_cols})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra información del conjunto de datos cargados\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = df_num.describe()\n",
    "summary = summary.transpose()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dada la cantidad de recursos que consume la carga del conjunto de datos de entrenamiento de tipo categórico\n",
    "# solo se leen los 10000 primeros registros para realizar un análisis rápido\n",
    "\n",
    "df_categ = pd.read_csv('train_categorical.csv', nrows=10000 ,low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categ.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df_categ.describe()\n",
    "summary = summary.transpose()\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dada la cantidad de recursos que consume la carga de del conjunto de datos de entrenamiento de tipo categórico\n",
    "# solo se leen los 10000 primeros registros para realizar un análisis rápido\n",
    "\n",
    "df_date = pd.read_csv('train_date.csv', nrows=10000 ,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df_date.describe()\n",
    "summary = summary.transpose()\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Análisis de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Se muestra un análisis estadístico para los atributos numéricos\n",
    "df_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se calcula el porcentaje de resultados de piezas correctas e incorrectas en los datos:\n",
    "df_num[\"Response\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra en formato gráfico la distribución de los resultados para evidenciar el desbalanceo en los datos\n",
    "\n",
    "ax = df_num[\"Response\"].value_counts().to_frame().plot(kind='bar')\n",
    "\n",
    "totals = []\n",
    "\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_height())\n",
    "\n",
    "total = sum(totals)\n",
    "\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.05, i.get_height()+.5, \\\n",
    "            str(round((i.get_height()/total)*100, 2))+'%', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se sustituyen los valores nulos por la media en los datos\n",
    "df_num.fillna(df_num.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se separan los datos entre las variables independientes y la variable dependiente\n",
    "X = df_num.drop('Response',1)\n",
    "y = df_num['Response']\n",
    "\n",
    "# Se separan el conjunto en datos de entrenamiento (80%) y datos de test (20%) \n",
    "# Debido a la baja representación de casos de fallos, se utiliza el parámetro stratify para asegurar que \n",
    "# ambas clases están representadas en el conjunto de datos de test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuación, se normalizan ambos conjuntos de datos para que estén representados en la misma escala \n",
    "# y por lo tanto no tomen más importancia unos que otros.\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica la reducción de dimensionalidad tanto a los datos de entrenamiento como a los de test\n",
    "# Se utiliza como parámetro un 98% de explicación de la varianza en lugar de determinar los componentes\n",
    "pca = PCA(0.98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica el mapeo al conjunto de datos de entrenamiento\n",
    "X_train_pca = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra el número de componentes calculado para al 98% de explicación de la varianza\n",
    "print ( \"Componentes para un 98% de explicación de varianza:   \", pca.n_components_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica el mapeo al conjunto de datos de test\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se utiliza el modelo XGBoost para obtener las características importantes\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestra gráficamente el top 20 de características más importantes\n",
    "plot_importance(xgb_model,max_num_features = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se toman las 500 características más importantes para el conjunto de datos\n",
    "selection = SelectFromModel(xgb_model, threshold=-np.inf, max_features=500, prefit=True)\n",
    "X_train_xgb = selection.transform(X_train)\n",
    "X_test_xgb = selection.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_xgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Técnicas de muestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Se aplican las técnicas de muestreo sobre los datos obtenidos con la aplicación del PCA\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_pca = RandomUnderSampler(random_state=2020)\n",
    "X_train_rus_pca, y_train_rus_pca = rus_pca.fit_resample(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pca = SMOTE(sampling_strategy='minority',random_state=2020)\n",
    "X_train_sm_pca, y_train_sm_pca = sm_pca.fit_resample(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "y_vals_rus_pca, counts_rus_pca = np.unique(y_train_rus_pca, return_counts=True)\n",
    "y_vals_sm_pca, counts_sm_pca = np.unique(y_train_sm_pca, return_counts=True)\n",
    "\n",
    "print('Clases en conjunto de entrenamiento:',dict(zip(y_vals, counts)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con PCA y RandomUnderSampler:',dict(zip(y_vals_rus_pca, counts_rus_pca)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con PCA y SMOTE:',dict(zip(y_vals_sm_pca, counts_sm_pca)),'\\n',\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato gráfico para evidenciar la corrección del desbalanceo en los datos de PCA y uno de los métodos\n",
    "\n",
    "ax = y_train_rus_pca.value_counts().to_frame().plot(kind='bar')\n",
    "\n",
    "totals = []\n",
    "\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_height())\n",
    "\n",
    "total = sum(totals)\n",
    "\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.05, i.get_height()+.5, \\\n",
    "            str(round((i.get_height()/total)*100, 2))+'%', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rus_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Se aplican las técnicas de muestreo sobre los datos obtenidos con la aplicación del XGBoost\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_xgb = RandomUnderSampler(random_state=2020)\n",
    "X_train_rus_xgb, y_train_rus_xgb = rus_xgb.fit_resample(X_train_xgb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_xgb = SMOTE(sampling_strategy='minority',random_state=2020)\n",
    "X_train_sm_xgb, y_train_sm_xgb = sm_xgb.fit_resample(X_train_xgb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vals_rus_xgb, counts_rus_xgb = np.unique(y_train_rus_xgb, return_counts=True)\n",
    "y_vals_sm_xgb, counts_sm_xgb = np.unique(y_train_sm_xgb, return_counts=True)\n",
    "\n",
    "print('Clases en conjunto de entrenamiento:',dict(zip(y_vals, counts)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con XGB y RandomUnderSampler:',dict(zip(y_vals_rus_xgb, counts_rus_xgb)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con XGB y SMOTE:',dict(zip(y_vals_sm_xgb, counts_sm_xgb)),'\\n',\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato gráfico para evidenciar la corrección del desbalanceo en los datos de XGBoost y uno de los métodos\n",
    "\n",
    "ax = y_train_rus_xgb.value_counts().to_frame().plot(kind='bar')\n",
    "\n",
    "totals = []\n",
    "\n",
    "for i in ax.patches:\n",
    "    totals.append(i.get_height())\n",
    "\n",
    "total = sum(totals)\n",
    "\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x()+.05, i.get_height()+.5, \\\n",
    "            str(round((i.get_height()/total)*100, 2))+'%', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rus_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm_xgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Dada la gran cantidad de registros obtenidos en los metodos de sobremuestreo, antes de pasar al modelado, vamos a analizar si realmente necesitamos tantos datos.\n",
    "\n",
    "Para ello se realiza el siguiente análisis:\n",
    "<ul>\n",
    "<li>Submuestreo aleatorio de la clase negativa con diferentes tamaños respecto a los casos positivos (1:2, 1:5, 1:10, 1:15)</li>\n",
    "<li>A continuación, aplicar sobremuestreo de la clase negativa y aprender un modelo</li>\n",
    "</ul>    \n",
    "    \n",
    "Este análisis se realiza con 10 submuestreos aleatorios diferentes para evitar sesgo en las muestras.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO. Revisar y mejorar disposición del código\n",
    "start_time = time.time()\n",
    "ratios=[1/2, 1/5, 1/10, 1/15]\n",
    "for ratio in ratios:\n",
    "    acc_scores    = []\n",
    "    prec_scores   = []\n",
    "    recall_scores = []\n",
    "    f1_scores     = []\n",
    "    mcc_scores    = [] \n",
    "    for i in range(10):\n",
    "        rus = RandomUnderSampler(sampling_strategy=ratio, random_state=i)\n",
    "        X_train_rus, y_train_rus = rus.fit_resample(X_train_pca, y_train)\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Tamaño resultado submuestreo: {}\\n\".format(1/ratio, i, X_train_rus.shape))\n",
    "        sm = SMOTE(sampling_strategy='minority',random_state=i)\n",
    "        X_train_rus_sm, y_train_rus_sm = sm.fit_resample(X_train_rus, y_train_rus)\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Tamaño resultado sobremuestreo: {}\\n\".format(1/ratio, i, X_train_rus_sm.shape))\n",
    "        rf_clf_rus_sm = ensemble.RandomForestClassifier(n_estimators=50, random_state=i, n_jobs=3)\n",
    "        rf_clf_rus_sm_pca = rf_clf_rus_sm.fit(X_train_rus_sm, y_train_rus_sm)\n",
    "        y_pred_rf_rus_sm_pca = rf_clf_rus_sm_pca.predict(X_test_pca)\n",
    "        acc = accuracy_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        prec = precision_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        rec = recall_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        f1s = f1_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        mcc = matthews_corrcoef(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Accuracy:  {:.2f}\\n\".format(1/ratio, i, acc))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Precision: {:.2f}\\n\".format(1/ratio, i, prec))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Recall:    {:.2f}\\n\".format(1/ratio, i, rec))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. F1 score:  {:.2f}\\n\".format(1/ratio, i, f1s))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. MCC:       {:.2f}\\n\".format(1/ratio, i, mcc))\n",
    "        acc_scores.append(acc)\n",
    "        prec_scores.append(prec)\n",
    "        recall_scores.append(rec)\n",
    "        f1_scores.append(f1s)\n",
    "        mcc_scores.append(mcc)\n",
    "    print(\"Ratio: {:.2f}x). Accuracy promedio:  {:.2f}\\n\".format(1/ratio, np.mean(acc_scores)))\n",
    "    print(\"Ratio: {:.2f}x). Precision promedio: {:.2f}\\n\".format(1/ratio, np.mean(prec_scores)))\n",
    "    print(\"Ratio: {:.2f}x). Recall promedio:    {:.2f}\\n\".format(1/ratio, np.mean(recall_scores)))\n",
    "    print(\"Ratio: {:.2f}x). F1 score promedio:  {:.2f}\\n\".format(1/ratio, np.mean(f1_scores)))\n",
    "    print(\"Ratio: {:.2f}x). MCC promedio:       {:.2f}\\n\\n\\n\".format(1/ratio, np.mean(mcc_scores)))\n",
    "    \n",
    "print(\"--- %s segundos ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Se amplia el experimiento a analizar los resultados para los ratios 1:20, 1:30 y 1:50\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO. Revisar y mejorar disposición del código\n",
    "start_time = time.time()\n",
    "ratios=[1/20, 1/30, 1/50]\n",
    "for ratio in ratios:\n",
    "    acc_scores    = []\n",
    "    prec_scores   = []\n",
    "    recall_scores = []\n",
    "    f1_scores     = []\n",
    "    mcc_scores    = [] \n",
    "    for i in range(10):\n",
    "        rus = RandomUnderSampler(sampling_strategy=ratio, random_state=i)\n",
    "        X_train_rus, y_train_rus = rus.fit_resample(X_train_pca, y_train)\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Tamaño resultado submuestreo: {}\\n\".format(1/ratio, i, X_train_rus.shape))\n",
    "        sm = SMOTE(sampling_strategy='minority',random_state=i)\n",
    "        X_train_rus_sm, y_train_rus_sm = sm.fit_resample(X_train_rus, y_train_rus)\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Tamaño resultado sobremuestreo: {}\\n\".format(1/ratio, i, X_train_rus_sm.shape))\n",
    "        rf_clf_rus_sm = ensemble.RandomForestClassifier(n_estimators=50, random_state=i, n_jobs=3)\n",
    "        rf_clf_rus_sm_pca = rf_clf_rus_sm.fit(X_train_rus_sm, y_train_rus_sm)\n",
    "        y_pred_rf_rus_sm_pca = rf_clf_rus_sm_pca.predict(X_test_pca)\n",
    "        acc = accuracy_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        prec = precision_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        rec = recall_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        f1s = f1_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        mcc = matthews_corrcoef(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Accuracy:  {:.2f}\\n\".format(1/ratio, i, acc))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Precision: {:.2f}\\n\".format(1/ratio, i, prec))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Recall:    {:.2f}\\n\".format(1/ratio, i, rec))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. F1 score:  {:.2f}\\n\".format(1/ratio, i, f1s))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. MCC:       {:.2f}\\n\".format(1/ratio, i, mcc))\n",
    "        acc_scores.append(acc)\n",
    "        prec_scores.append(prec)\n",
    "        recall_scores.append(rec)\n",
    "        f1_scores.append(f1s)\n",
    "        mcc_scores.append(mcc)\n",
    "    print(\"Ratio: {:.2f}x). Accuracy promedio:  {:.2f}\\n\".format(1/ratio, np.mean(acc_scores)))\n",
    "    print(\"Ratio: {:.2f}x). Precision promedio: {:.2f}\\n\".format(1/ratio, np.mean(prec_scores)))\n",
    "    print(\"Ratio: {:.2f}x). Recall promedio:    {:.2f}\\n\".format(1/ratio, np.mean(recall_scores)))\n",
    "    print(\"Ratio: {:.2f}x). F1 score promedio:  {:.2f}\\n\".format(1/ratio, np.mean(f1_scores)))\n",
    "    print(\"Ratio: {:.2f}x). MCC promedio:       {:.2f}\\n\\n\\n\".format(1/ratio, np.mean(mcc_scores)))\n",
    "    \n",
    "print(\"--- %s segundos ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Al observar que el resultado sigue mejorando, se amplia el experimiento a analizar los resultados para los ratios 1:100, 1:150 y 1:170\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO. Revisar y mejorar disposición del código\n",
    "start_time = time.time()\n",
    "ratios=[1/100, 1/150, 1/170]\n",
    "for ratio in ratios:\n",
    "    acc_scores    = []\n",
    "    prec_scores   = []\n",
    "    recall_scores = []\n",
    "    f1_scores     = []\n",
    "    mcc_scores    = [] \n",
    "    for i in range(10):\n",
    "        rus = RandomUnderSampler(sampling_strategy=ratio, random_state=i)\n",
    "        X_train_rus, y_train_rus = rus.fit_resample(X_train_pca, y_train)\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Tamaño resultado submuestreo: {}\\n\".format(1/ratio, i, X_train_rus.shape))\n",
    "        sm = SMOTE(sampling_strategy='minority',random_state=i)\n",
    "        X_train_rus_sm, y_train_rus_sm = sm.fit_resample(X_train_rus, y_train_rus)\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Tamaño resultado sobremuestreo: {}\\n\".format(1/ratio, i, X_train_rus_sm.shape))\n",
    "        rf_clf_rus_sm = ensemble.RandomForestClassifier(n_estimators=50, random_state=i, n_jobs=3)\n",
    "        rf_clf_rus_sm_pca = rf_clf_rus_sm.fit(X_train_rus_sm, y_train_rus_sm)\n",
    "        y_pred_rf_rus_sm_pca = rf_clf_rus_sm_pca.predict(X_test_pca)\n",
    "        acc = accuracy_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        prec = precision_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        rec = recall_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        f1s = f1_score(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        mcc = matthews_corrcoef(y_test,y_pred_rf_rus_sm_pca)*100\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Accuracy:  {:.2f}\\n\".format(1/ratio, i, acc))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Precision: {:.2f}\\n\".format(1/ratio, i, prec))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. Recall:    {:.2f}\\n\".format(1/ratio, i, rec))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. F1 score:  {:.2f}\\n\".format(1/ratio, i, f1s))\n",
    "        print(\"Ratio: {:.2f}x). Iteración: {}. MCC:       {:.2f}\\n\".format(1/ratio, i, mcc))\n",
    "        acc_scores.append(acc)\n",
    "        prec_scores.append(prec)\n",
    "        recall_scores.append(rec)\n",
    "        f1_scores.append(f1s)\n",
    "        mcc_scores.append(mcc)\n",
    "    print(\"Ratio: {:.2f}x). Accuracy promedio:  {:.2f}\\n\".format(1/ratio, np.mean(acc_scores)))\n",
    "    print(\"Ratio: {:.2f}x). Precision promedio: {:.2f}\\n\".format(1/ratio, np.mean(prec_scores)))\n",
    "    print(\"Ratio: {:.2f}x). Recall promedio:    {:.2f}\\n\".format(1/ratio, np.mean(recall_scores)))\n",
    "    print(\"Ratio: {:.2f}x). F1 score promedio:  {:.2f}\\n\".format(1/ratio, np.mean(f1_scores)))\n",
    "    print(\"Ratio: {:.2f}x). MCC promedio:       {:.2f}\\n\\n\\n\".format(1/ratio, np.mean(mcc_scores)))\n",
    "    \n",
    "print(\"--- %s segundos ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Para los modelos, se tomara la técnica de muestreo con ratio 1:15 y ratio 1:50 de números positivos sobre los datos obtenidos con la aplicación del PCA y XGBoost\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 1/15\n",
    "\n",
    "rus_pca_15 = RandomUnderSampler(sampling_strategy=ratio, random_state=2020)\n",
    "X_train_rus_pca_15, y_train_rus_pca_15 = rus_pca_15.fit_resample(X_train_pca, y_train)\n",
    "        \n",
    "rus_sm_pca_15 = SMOTE(sampling_strategy='minority',random_state=2020)\n",
    "X_train_rus_sm_pca_15, y_train_rus_sm_pca_15 = rus_sm_pca_15.fit_resample(X_train_rus_pca_15, y_train_rus_pca_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_xgb_15 = RandomUnderSampler(sampling_strategy=ratio, random_state=2020)\n",
    "X_train_rus_xgb_15, y_train_rus_xgb_15 = rus_xgb_15.fit_resample(X_train_xgb, y_train)\n",
    "        \n",
    "rus_sm_xgb_15 = SMOTE(sampling_strategy='minority',random_state=2020)\n",
    "X_train_rus_sm_xgb_15, y_train_rus_sm_xgb_15 = rus_sm_xgb_15.fit_resample(X_train_rus_xgb_15, y_train_rus_xgb_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 1/50\n",
    "\n",
    "rus_pca_50 = RandomUnderSampler(sampling_strategy=ratio, random_state=2020)\n",
    "X_train_rus_pca_50, y_train_rus_pca_50 = rus_pca_50.fit_resample(X_train_pca, y_train)\n",
    "        \n",
    "rus_sm_pca_50 = SMOTE(sampling_strategy='minority',random_state=2020)\n",
    "X_train_rus_sm_pca_50, y_train_rus_sm_pca_50 = rus_sm_pca_50.fit_resample(X_train_rus_pca_50, y_train_rus_pca_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_xgb_50 = RandomUnderSampler(sampling_strategy=ratio, random_state=2020)\n",
    "X_train_rus_xgb_50, y_train_rus_xgb_50 = rus_xgb_50.fit_resample(X_train_xgb, y_train)\n",
    "        \n",
    "rus_sm_xgb_50 = SMOTE(sampling_strategy='minority',random_state=2020)\n",
    "X_train_rus_sm_xgb_50, y_train_rus_sm_xgb_50 = rus_sm_xgb_50.fit_resample(X_train_rus_xgb_50, y_train_rus_xgb_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actualizamos los datos incluyendo el nuevo método de muestreo\n",
    "y_vals_rus_sm_pca_15, counts_rus_sm_pca_15 = np.unique(y_train_rus_sm_pca_15, return_counts=True)\n",
    "y_vals_rus_sm_pca_50, counts_rus_sm_pca_50 = np.unique(y_train_rus_sm_pca_50, return_counts=True)\n",
    "\n",
    "print('Clases en conjunto de entrenamiento:',dict(zip(y_vals, counts)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con PCA y RandomUnderSampler (1:1):',dict(zip(y_vals_rus_pca, counts_rus_pca)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con PCA y SMOTE (1:171):',dict(zip(y_vals_sm_pca, counts_sm_pca)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con PCA y RandomUnderSampler+SMOTE (1:15):',dict(zip(y_vals_rus_sm_pca_15, counts_rus_sm_pca_15)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con PCA y RandomUnderSampler+SMOTE (1:50):',dict(zip(y_vals_rus_sm_pca_50, counts_rus_sm_pca_50)),'\\n',\n",
    "     )\n",
    "\n",
    "y_vals_rus_sm_xgb_15, counts_rus_sm_xgb_15 = np.unique(y_train_rus_sm_xgb_15, return_counts=True)\n",
    "y_vals_rus_sm_xgb_50, counts_rus_sm_xgb_50 = np.unique(y_train_rus_sm_xgb_50, return_counts=True)\n",
    "\n",
    "print('Clases en conjunto de entrenamiento:',dict(zip(y_vals, counts)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con XGB y RandomUnderSampler (1:1):',dict(zip(y_vals_rus_xgb, counts_rus_xgb)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con XGB y SMOTE (1:171):',dict(zip(y_vals_sm_xgb, counts_sm_xgb)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con XGB y RandomUnderSampler+SMOTE (1:15):',dict(zip(y_vals_rus_sm_xgb_15, counts_rus_sm_xgb_15)),'\\n',\n",
    "      'Clases en conjunto de entrenamiento con XGB y RandomUnderSampler+SMOTE (1:50):',dict(zip(y_vals_rus_sm_xgb_50, counts_rus_sm_xgb_50)),'\\n',\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rus_sm_pca_15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rus_sm_xgb_15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rus_sm_pca_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rus_sm_xgb_50.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">La idea básica del bagging es utilizar el conjunto de entrenamiento original para generar centenares o miles de conjuntos similares usando muestreo con reemplazo. En este concepto está basado el algoritmo Random Forest, la combinación de varios árboles de decisión, cada uno entrenado con una realización diferente de los datos. La decisión final del clasificador combinado (la Random Forest) se toma por mayoría, dando el mismo peso a todas las decisiones parciales tomadas por los clasificadores base (los árboles).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Para decidir cuáles son los hiperparámetros óptimos se utiliza una búsqueda de rejilla (grid search), es decir, se entrena un modelo para cada combinación de hiperparámetros posible y se evalua utilizando validación cruzada (cross validation) con 3 particiones estratificadas. \n",
    "Posteriormente se selecciona la combinación de hiperparámetros que mejor resultados haya dado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\" : [50, 100, 200],\n",
    "    \"max_depth\"    : [8, 10, 20],\n",
    "    \"random_state\" : [2020],\n",
    "}\n",
    "\n",
    "rf_clf_gs = GridSearchCV(ensemble.RandomForestClassifier(), param_grid=param_grid, cv=3, pre_dispatch=6, n_jobs=3,scoring='f1',verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se toma como conjunto de entrenamiento para determinar los mejores parámetros los resultantes de PCA + combinar los muestreos \n",
    "rf_clf_gs_rus_sm_pca_15 = rf_clf_gs.fit(X_train_rus_sm_pca_15, y_train_rus_sm_pca_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_gs_rus_sm_pca_15.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = rf_clf_gs_rus_sm_pca_15.cv_results_[\"mean_test_score\"]\n",
    "stds = rf_clf_gs_rus_sm_pca_15.cv_results_[\"std_test_score\"]\n",
    "params = rf_clf_gs_rus_sm_pca_15.cv_results_['params']\n",
    "ranks = rf_clf_gs_rus_sm_pca_15.cv_results_['rank_test_score']\n",
    "\n",
    "for rank, mean, std, pms in zip(ranks, means, stds, params):\n",
    "    print(\"{}) Precisión media: {:.2f} +/- {:.2f} con parámetros {}\".format(rank, mean*100, std*100, pms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se toma como conjunto de entrenamiento para determinar los mejores parámetros los resultantes de XGB + combinar los muestreos \n",
    "rf_clf_gs_rus_sm_xgb_15 = rf_clf_gs.fit(X_train_rus_sm_xgb_15, y_train_rus_sm_xgb_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_gs_rus_sm_xgb_15.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = rf_clf_gs_rus_sm_xgb_15.cv_results_[\"mean_test_score\"]\n",
    "stds = rf_clf_gs_rus_sm_xgb_15.cv_results_[\"std_test_score\"]\n",
    "params = rf_clf_gs_rus_sm_xgb_15.cv_results_['params']\n",
    "ranks = rf_clf_gs_rus_sm_xgb_15.cv_results_['rank_test_score']\n",
    "\n",
    "for rank, mean, std, pms in zip(ranks, means, stds, params):\n",
    "    print(\"{}) Precisión media: {:.2f} +/- {:.2f} con parámetros {}\".format(rank, mean*100, std*100, pms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Ejecución inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "A partir de los conjuntos de datos obtenidos de la reducción dimensional y el muestreo, se entrena un modelo <i>Random Forest</i> con los mejores parámetros obtenidos del <i>grid search</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = ensemble.RandomForestClassifier(n_estimators=rf_clf_gs_rus_sm_pca_15.best_params_[\"n_estimators\"], max_depth=rf_clf_gs_rus_sm_pca_15.best_params_[\"max_depth\"], random_state=rf_clf_gs_rus_sm_pca_15.best_params_[\"random_state\"], n_jobs=3, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    Ramdom Forest con el conjunto de datos PCA y RandomUnderSampler\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cfl_rus_pca = rf_clf.fit(X_train_rus_pca, y_train_rus_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_rus_pca = rf_cfl_rus_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se muestran los resultados a través de la precisión de las predicciones y la matriz de confusión de cada modelo\n",
    "# Se utiliza una función para mostrar de forma gráfica la matriz de confusión\n",
    "# NOTA: código extraído de 20182 M2.855 PEC 3 modificado para poder mostrar los datos normalizados o sin normalizar\n",
    "\n",
    "def plot_confusion_matrix_custom(cm, normalize):\n",
    "    classes = [\"0\", \"1\"]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "   \n",
    "    cmap=plt.cm.Blues\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Real')\n",
    "    plt.xlabel('Predicción')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf_rus_pca = confusion_matrix(y_test, y_pred_rf_rus_pca)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_rf_rus_pca, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_rf_rus_pca, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_rf_rus_pca)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_rf_rus_pca)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_rf_rus_pca)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_rf_rus_pca)*100)  \n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_rf_rus_pca)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    Ramdom Forest con el conjunto de datos PCA y SMOTE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cfl_sm_pca = rf_clf.fit(X_train_sm_pca, y_train_sm_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_sm_pca = rf_cfl_sm_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf_sm_pca = confusion_matrix(y_test, y_pred_rf_sm_pca)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_rf_sm_pca,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_rf_sm_pca,True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_rf_sm_pca)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_rf_sm_pca)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_rf_sm_pca)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_rf_sm_pca)*100)  \n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_rf_sm_pca)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    Ramdom Forest con el conjunto de datos PCA y RandomUnderSampler + SMOTE (1:15)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cfl_rus_sm_pca_15 = rf_clf.fit(X_train_rus_sm_pca_15, y_train_rus_sm_pca_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_rus_sm_pca_15 = rf_cfl_rus_sm_pca_15.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf_rus_sm_pca_15 = confusion_matrix(y_test, y_pred_rf_rus_sm_pca_15)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_rf_rus_sm_pca_15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_rf_rus_sm_pca_15, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_rf_rus_sm_pca_15)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_rf_rus_sm_pca_15)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_rf_rus_sm_pca_15)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_rf_rus_sm_pca_15)*100)  \n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_rf_rus_sm_pca_15)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    Ramdom Forest con el conjunto de datos PCA y RandomUnderSampler + SMOTE (1:50)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cfl_rus_sm_pca_50 = rf_clf.fit(X_train_rus_sm_pca_50, y_train_rus_sm_pca_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_rus_sm_pca_50 = rf_cfl_rus_sm_pca_50.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf_rus_sm_pca_50 = confusion_matrix(y_test, y_pred_rf_rus_sm_pca_50)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_rf_rus_sm_pca_50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_rf_rus_sm_pca_50, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_rf_rus_sm_pca_50)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_rf_rus_sm_pca_50)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_rf_rus_sm_pca_50)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_rf_rus_sm_pca_50)*100)  \n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_rf_rus_sm_pca_50)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    Ramdom Forest con el conjunto de datos XGBoost y RandomUnderSampler\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cfl_rus_xgb = rf_clf.fit(X_train_rus_xgb, y_train_rus_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_rus_xgb = rf_cfl_rus_xgb.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf_rus_xgb = confusion_matrix(y_test, y_pred_rf_rus_xgb)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_rf_rus_xgb, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_rf_rus_xgb, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_rf_rus_xgb)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_rf_rus_xgb)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_rf_rus_xgb)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_rf_rus_xgb)*100)  \n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_rf_rus_xgb)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    Ramdom Forest con el conjunto de datos XGBoost y SMOTE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cfl_sm_xgb = rf_clf.fit(X_train_sm_xgb, y_train_sm_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_sm_xgb = rf_cfl_sm_xgb.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf_sm_xgb = confusion_matrix(y_test, y_pred_rf_sm_xgb)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_rf_sm_xgb, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_rf_sm_xgb, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_rf_sm_xgb)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_rf_sm_xgb)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_rf_sm_xgb)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_rf_sm_xgb)*100)  \n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_rf_sm_xgb)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    Ramdom Forest con el conjunto de datos XGBoost y RandomUnderSampler + SMOTE (1:15)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cfl_rus_sm_xgb_15 = rf_clf.fit(X_train_rus_sm_xgb_15, y_train_rus_sm_xgb_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_rus_sm_xgb_15 = rf_cfl_rus_sm_xgb_15.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf_rus_sm_xgb_15 = confusion_matrix(y_test, y_pred_rf_rus_sm_xgb_15)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_rf_rus_sm_xgb_15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_rf_rus_sm_xgb_15, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_rf_rus_sm_xgb_15)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_rf_rus_sm_xgb_15)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_rf_rus_sm_xgb_15)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_rf_rus_sm_xgb_15)*100)  \n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_rf_rus_sm_xgb_15)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    Ramdom Forest con el conjunto de datos XGBoost y RandomUnderSampler + SMOTE (1:50)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cfl_rus_sm_xgb_50 = rf_clf.fit(X_train_rus_sm_xgb_50, y_train_rus_sm_xgb_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_rus_sm_xgb_50 = rf_cfl_rus_sm_xgb_50.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf_rus_sm_xgb_50 = confusion_matrix(y_test, y_pred_rf_rus_sm_xgb_50)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_rf_rus_sm_xgb_50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_rf_rus_sm_xgb_50, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_rf_rus_sm_xgb_50)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_rf_rus_sm_xgb_50)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_rf_rus_sm_xgb_50)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_rf_rus_sm_xgb_50)*100)  \n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_rf_rus_sm_xgb_50)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. eXtreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "En el sistema de Boosting se combinan varios clasificadores débiles secuencialmente, y en cada uno de ellos se da más peso a los datos que han sido erróneamente clasificados en las combinaciones anteriores, para que se concentre así en los casos más difíciles de resolver.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "Para decidir cuáles son los hiperparámetros óptimos se utiliza una búsqueda de rejilla (grid search), es decir, se entrena un modelo para cada combinación de hiperparámetros posible y se evalua utilizando validación cruzada (cross validation) con 3 particiones estratificadas. \n",
    "Posteriormente se selecciona la combinación de hiperparámetros que mejor resultados haya dado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\"     : [50, 100, 200],\n",
    "    \"max_depth\"        : [8, 10, 20],\n",
    "    \"min_child_weight\" : [6, 8, 10],\n",
    "    \"random_state\"     : [2020],\n",
    "}\n",
    "\n",
    "xgb_clf_gs = GridSearchCV(XGBClassifier(), param_grid=param_grid, scoring='f1', cv=3, pre_dispatch=6, n_jobs=3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se toma como conjunto de entrenamiento para determinar los mejores parámetros los resultantes de PCA + combinar los muestreos \n",
    "xgb_clf_gs_rus_sm_pca_15 = xgb_clf_gs.fit(X_train_rus_sm_pca_15, y_train_rus_sm_pca_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_gs_rus_sm_pca_15.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = xgb_clf_gs_rus_sm_pca_15.cv_results_[\"mean_test_score\"]\n",
    "stds = xgb_clf_gs_rus_sm_pca_15.cv_results_[\"std_test_score\"]\n",
    "params = xgb_clf_gs_rus_sm_pca_15.cv_results_['params']\n",
    "ranks = xgb_clf_gs_rus_sm_pca_15.cv_results_['rank_test_score']\n",
    "\n",
    "for rank, mean, std, pms in zip(ranks, means, stds, params):\n",
    "    print(\"{}) Precisión media: {:.2f} +/- {:.2f} con parámetros {}\".format(rank, mean*100, std*100, pms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se toma como conjunto de entrenamiento para determinar los mejores parámetros los resultantes de XGB + combinar los muestreos \n",
    "xgb_clf_gs_rus_sm_xgb_15 = xgb_clf_gs.fit(X_train_rus_sm_xgb_15, y_train_rus_sm_xgb_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_gs_rus_sm_xgb_15.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = xgb_clf_gs_rus_sm_xgb_15.cv_results_[\"mean_test_score\"]\n",
    "stds = xgb_clf_gs_rus_sm_xgb_15.cv_results_[\"std_test_score\"]\n",
    "params = xgb_clf_gs_rus_sm_xgb_15.cv_results_['params']\n",
    "ranks = xgb_clf_gs_rus_sm_xgb_15.cv_results_['rank_test_score']\n",
    "\n",
    "for rank, mean, std, pms in zip(ranks, means, stds, params):\n",
    "    print(\"{}) Precisión media: {:.2f} +/- {:.2f} con parámetros {}\".format(rank, mean*100, std*100, pms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Ejecución inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "A partir de los conjuntos de datos obtenidos de la reducción dimensional y el muestreo, se entrena un modelo <i>XGBoost</i> con los mejores parámetros obtenidos del <i>grid search</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=xgb_clf_gs_rus_sm_pca_15.best_params_[\"n_estimators\"], max_depth=xgb_clf_gs_rus_sm_pca_15.best_params_[\"max_depth\"], min_child_weight=xgb_clf_gs_rus_sm_pca_15.best_params_[\"min_child_weight\"], random_state=xgb_clf_gs_rus_sm_pca_15.best_params_[\"random_state\"], subsample=0.8, scoring='f1', cv=3, pre_dispatch=6, n_jobs=3, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    XGBoost con el conjunto de datos PCA y RandomUnderSampler\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl_rus_pca = xgb_clf.fit(X_train_rus_pca, y_train_rus_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_rus_pca = xgb_cfl_rus_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb_rus_pca = confusion_matrix(y_test, y_pred_xgb_rus_pca)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_xgb_rus_pca, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_xgb_rus_pca, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_xgb_rus_pca)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_xgb_rus_pca)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_xgb_rus_pca)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_xgb_rus_pca)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_xgb_rus_pca)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    XGBoost con el conjunto de datos PCA y SMOTE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl_sm_pca = xgb_clf.fit(X_train_sm_pca, y_train_sm_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_sm_pca = xgb_cfl_sm_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb_sm_pca = confusion_matrix(y_test, y_pred_xgb_sm_pca)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_xgb_sm_pca, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_xgb_sm_pca, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_xgb_sm_pca)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_xgb_sm_pca)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_xgb_sm_pca)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_xgb_sm_pca)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_xgb_sm_pca)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    XGBoost con el conjunto de datos PCA y RandomUnderSampler + SMOTE (1:15)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl_rus_sm_pca_15 = xgb_clf.fit(X_train_rus_sm_pca_15, y_train_rus_sm_pca_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_rus_sm_pca_15 = xgb_cfl_rus_sm_pca_15.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb_rus_sm_pca_15 = confusion_matrix(y_test, y_pred_xgb_rus_sm_pca_15)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_xgb_rus_sm_pca_15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_xgb_rus_sm_pca_15, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_xgb_rus_sm_pca_15)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_xgb_rus_sm_pca_15)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_xgb_rus_sm_pca_15)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_xgb_rus_sm_pca_15)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_xgb_rus_sm_pca_15)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    XGBoost con el conjunto de datos PCA y RandomUnderSampler + SMOTE (1:50)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl_rus_sm_pca_50 = xgb_clf.fit(X_train_rus_sm_pca_50, y_train_rus_sm_pca_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_rus_sm_pca_50 = xgb_cfl_rus_sm_pca_50.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb_rus_sm_pca_50 = confusion_matrix(y_test, y_pred_xgb_rus_sm_pca_50)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_xgb_rus_sm_pca_50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_xgb_rus_sm_pca_50, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_xgb_rus_sm_pca_50)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_xgb_rus_sm_pca_50)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_xgb_rus_sm_pca_50)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_xgb_rus_sm_pca_50)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_xgb_rus_sm_pca_50)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    XGBoost con el conjunto de datos XGBoost y RandomUnderSampler\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl_rus_xgb = xgb_clf.fit(X_train_rus_xgb, y_train_rus_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_rus_xgb = xgb_cfl_rus_xgb.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb_rus_xgb = confusion_matrix(y_test, y_pred_xgb_rus_xgb)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_xgb_rus_xgb, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_xgb_rus_xgb, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_xgb_rus_xgb)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_xgb_rus_xgb)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_xgb_rus_xgb)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_xgb_rus_xgb)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_xgb_rus_xgb)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    XGBoost con el conjunto de datos XGBoost y SMOTE\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl_sm_xgb = xgb_clf.fit(X_train_sm_xgb, y_train_sm_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_sm_xgb = xgb_cfl_sm_xgb.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb_sm_xgb = confusion_matrix(y_test, y_pred_xgb_sm_xgb)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_xgb_sm_xgb, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_xgb_sm_xgb, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_xgb_sm_xgb)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_xgb_sm_xgb)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_xgb_sm_xgb)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_xgb_sm_xgb)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_xgb_sm_xgb)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    XGBoost con el conjunto de datos XGBoost y y RandomUnderSampler + SMOTE (1:15)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl_rus_sm_xgb_15 = xgb_clf.fit(X_train_rus_sm_xgb_15, y_train_rus_sm_xgb_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_rus_sm_xgb_15 = xgb_cfl_rus_sm_xgb_15.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb_rus_sm_xgb_15 = confusion_matrix(y_test, y_pred_xgb_rus_sm_xgb_15)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_xgb_rus_sm_xgb_15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_xgb_rus_sm_xgb_15, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_xgb_rus_sm_xgb_15)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_xgb_rus_sm_xgb_15)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_xgb_rus_sm_xgb_15)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_xgb_rus_sm_xgb_15)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_xgb_rus_sm_xgb_15)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">    \n",
    "    XGBoost con el conjunto de datos XGBoost y y RandomUnderSampler + SMOTE (1:50)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cfl_rus_sm_xgb_50 = xgb_clf.fit(X_train_rus_sm_xgb_50, y_train_rus_sm_xgb_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_rus_sm_xgb_50 = xgb_cfl_rus_sm_xgb_50.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_xgb_rus_sm_xgb_50 = confusion_matrix(y_test, y_pred_xgb_rus_sm_xgb_50)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_xgb_rus_sm_xgb_50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_xgb_rus_sm_xgb_50, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_xgb_rus_sm_xgb_50)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_xgb_rus_sm_xgb_50)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_xgb_rus_sm_xgb_50)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_xgb_rus_sm_xgb_50)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_xgb_rus_sm_xgb_50)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\"> \n",
    "En base a estos resultados, cabe la pregunta de: dato que se están utilizando dos modelos diferentes, si se combinan, ¿mejora algo? \n",
    "\n",
    "En este apartado se explora dentro de la combinación secuencial de modelos la técnica del stacking para obtener un clasificador combinando de ambos modelos ya utilizados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Combinación secuencial de modelos stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\"> \n",
    "El stacking es una técnica de combinación secuencial de clasificadores bases diferentes a través de un meta-clasificador.\n",
    "\n",
    "En el caso concreto de este trabajo y por las limitaciones de recursos, se entrena el clasificador de stacking utilizando los conjuntos de datos de la combinación de muestreo con ratio 1:15 y ratio 1:50 del número de positivos para los clasificadores empleados en la etapa del modelado.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se combinan los clasificadores en un mismo meta-clasificador \n",
    "\n",
    "estimators = [\n",
    "     ('rf', ensemble.RandomForestClassifier(n_estimators=rf_clf_gs_rus_sm_pca_15.best_params_[\"n_estimators\"], max_depth=rf_clf_gs_rus_sm_pca_15.best_params_[\"max_depth\"], random_state=rf_clf_gs_rus_sm_pca_15.best_params_[\"random_state\"], n_jobs=3, verbose=0)),\n",
    "     ('xgb', XGBClassifier(n_estimators=xgb_clf_gs_rus_sm_pca_15.best_params_[\"n_estimators\"], max_depth=xgb_clf_gs_rus_sm_pca_15.best_params_[\"max_depth\"], random_state=xgb_clf_gs_rus_sm_pca_15.best_params_[\"random_state\"], min_child_weight=xgb_clf_gs_rus_sm_xgb_15.best_params_[\"min_child_weight\"], subsample=0.8, scoring='f1', cv=3, pre_dispatch=6, n_jobs=3, verbose=0))\n",
    " ]\n",
    "\n",
    "stack_clf = StackingClassifier(estimators=estimators, cv=3, n_jobs=3, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\"> \n",
    "Ratio 1:15\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_cfl_rus_sm_xgb_15 = stack_clf.fit(X_train_rus_sm_xgb_15, y_train_rus_sm_xgb_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack_rus_sm_xgb_15 = stack_cfl_rus_sm_xgb_15.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_stack_rus_sm_xgb_15 = confusion_matrix(y_test, y_pred_stack_rus_sm_xgb_15)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_stack_rus_sm_xgb_15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_stack_rus_sm_xgb_15, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_stack_rus_sm_xgb_15)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_stack_rus_sm_xgb_15)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_stack_rus_sm_xgb_15)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_stack_rus_sm_xgb_15)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_stack_rus_sm_xgb_15)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\"> \n",
    "Ratio 1:50\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_cfl_rus_sm_xgb_50 = stack_clf.fit(X_train_rus_sm_xgb_50, y_train_rus_sm_xgb_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack_rus_sm_xgb_50 = stack_cfl_rus_sm_xgb_50.predict(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_stack_rus_sm_xgb_50 = confusion_matrix(y_test, y_pred_stack_rus_sm_xgb_50)  \n",
    "\n",
    "plot_confusion_matrix_custom(cm_stack_rus_sm_xgb_50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_custom(cm_stack_rus_sm_xgb_50, True)\n",
    "\n",
    "print('Accuracy:  ', accuracy_score(y_test,y_pred_stack_rus_sm_xgb_50)*100)  \n",
    "print('Precision: ', precision_score(y_test,y_pred_stack_rus_sm_xgb_50)*100)  \n",
    "print('Recall:    ', recall_score(y_test,y_pred_stack_rus_sm_xgb_50)*100)  \n",
    "print('F1 score:  ', f1_score(y_test,y_pred_stack_rus_sm_xgb_50)*100)\n",
    "print('MCC:       ', matthews_corrcoef(y_test,y_pred_stack_rus_sm_xgb_50)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
